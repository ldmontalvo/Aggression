---
title: "Aggression Interference with SEM and PCA"
author: "Daniel Montalvo"
date: "5/2/2022"
output: output=github_document
---

<center>

<h1>Exploratory Analysis for Playback Expriments</h1>

</center>

<center>

<h2>Luis Daniel Montalvo</h2>

</center>

### Introduction

Here, I am analyzing data from playback experiments carried out in 2018 to study aggressive interference using SEM.

```{r setup, include=FALSE}

rm(list=ls())

setwd("C:/Users/Daniel/Dropbox/Thesis/Aggressive Behavior/R")

load("GDM_data.RData")
load("GDM_out.RData")

```

#### Reading the data

```{r Reading Files and General Data Management, echo=FALSE}

## Reading the original data for the experiments
Exp.raw <- read.csv("Data.csv", sep=",", header=TRUE, stringsAsFactors = FALSE)
Exp.raw$Dist <- as.numeric(as.character(Exp.raw$Dist))

View(Exp.raw)

## Getting rid of others species other than wrens
Exp.wrens <- subset(Exp.raw,Exp.raw$Species == "BBWR" |
                      Exp.raw$Species == "FWR" |
                      Exp.raw$Species == "BBxFWR")

## Reading data for the description of experiments (metadata)
Meta.exp.raw <- read.csv("Exp.csv", sep=",", header=TRUE, as.is=T)

## Merging the experiments data and the metadata of the experiments
Exp.meta<-merge(Exp.wrens, Meta.exp.raw, by=c("Exp"))

View(Exp.meta)

## Getting the times in seconds as numeric
Exp.meta$Sec <- as.numeric(Exp.meta$Sec)

## Adding the a variable for the seconds that passed to the first FAP 
## The experiment last 3 min, but the time was recorded backwards, 
## so we rest 180 (3 mins) to make time forward.
## Exp.meta$Timing_sec2 <- 180 - Exp.meta$Timing_sec

## Installing necessary packages
install.packages("tidyverse")
library(tidyverse)

## Filtering only data in the time of the treatments
Exp.treat.filtered <- subset(Exp.meta, Exp.meta$Treatment == "BBWR" | 
                                       Exp.meta$Treatment == "FWR" |
                                       Exp.meta$Treatment == "Control")

## I also add environmental data below and it is explained with more detail
## Reading the data with spatial data (coor and precipitation)
env <- read.csv("Env.csv", sep=",", header=TRUE, as.is = T)

## I also add genetic data below, including data form structure and hybrid index
## Reading the data with spatial data and Genetic Cluster from Structure Analysis
gen.spatial <- read.csv("k4popfile.txt", sep="\t", header=TRUE, as.is = T)


### All data: Both treatments ####

## Merging all data
Exp.all2 <- merge(Exp.treat.filtered, env, by=c("Group"))

## Reading the descriptions of FAPs. We want to get rid of the non Aggressive FAPs
faps <- read.csv("fap.csv", sep=",", header=TRUE, stringsAsFactors = FALSE)

## Adding the information of FAPs categories
Exp.all2 <- merge(Exp.all2, faps[,c(1,3)], all.x=TRUE,  by.x="FAP", by.y="Code")

## Removing the rows with no Aggressive Behaviors
Exp.all2 <- Exp.all2[!grepl("No aggressive", Exp.all2$Category),]


## Since the response of the birds were in group, we use it as a unit or sample for 
## presenting the results. We create a unique code for Experiment, Group and Treatment
Exp.all2$Cod_sam <- paste(Exp.all2$Group, Exp.all2$Exp, Exp.all2$Treatment, sep=".")

## Extracting only rows with the shortest distance reached in the treatment
library(dplyr)
Exp.min <- Exp.all2 %>% 
  group_by(Pop, Group, Treatment, Cod_sam) %>%
  slice(which.min(Dist))

## We also use total (abundance) and unique (richness) number of FAPs
Exp.fap <- Exp.all2 %>%
  dplyr::group_by(Pop, Group, Treatment, Cod_sam) %>%
  dplyr::summarise(TFAP=length(FAP), 
            NFAP=length(unique(FAP)))


######################      MASTER DATAFRAME      ##############################
## Merging the FAPs variables and the distance and latency in the same dataframe
Exp.codes <- merge(Exp.min, Exp.fap, by="Cod_sam")
Exp.codes$Timing_sec <- as.numeric(Exp.codes$Timing_sec)
################################################################################


## Combining populations

## Copying the dataframe
Exp.gc <- Exp.codes

## Sites belonging to Genetic Populations
CZ <- c("Patricia Pilar", "Las Golondrinas", "Pedro Carbo", "PVM", "Chone")
CFP_N <- c("Calceta", "Montecristi", "Machalilla", "Manglares Churute")
CFP_S <- c("Arenillas", "Zapotillo", "Cazaderos")


## Sampling sites for CZ have CZ in column Pop
for(i in 1:length(CZ)){
Exp.gc$GC[Exp.gc$Pop.x == CZ[i]] <- "CZ"}


## Sampling sites for CFP_N have CFP_N in column Pop
for(i in 1:length(CFP_N)){
Exp.gc$GC[Exp.gc$Pop.x == CFP_N[i]] <- "CFP_N"}


## Sampling sites for CFP_S have CFP_S in column Pop
for(i in 1:length(CFP_S)){
Exp.gc$GC[Exp.gc$Pop.x == CFP_S[i]] <- "CFP_S"}


## Creating an order for Genetic Population
gc_order <- c("CZ", "CFP_N", "CFP_S")

## Order of Populations
Exp.gc$GC <- factor(Exp.gc$GC, levels=gc_order)


```


#### Working with Environmental Variables

```{r Getting the Environmental Variables, echo=FALSE}

################################################################################

## Spatial Analysis Packages
#install.packages(c("spdep", "sp", "raster","rgdal","ClimDatDownloadR", "rgeos", "envirem"), dependencies=TRUE)

## Statistical Packages
install.packages(c("Hmisc","PerformanceAnalytics"), dependencies=TRUE)
install.packages("Hmisc")


library(envirem) # Have to be called first to avoid conflict with raster packages
library(spdep)
library(raster)
library(rgdal)
library(ClimDatDownloadR)
library(rgeos)
library(sp)
library(Hmisc)
library(PerformanceAnalytics)

View(env)

## Getting name of groups and coodinates
gr.coor <- env[,c("Group", "Lat", "Long")]

## Making the coordinates numeric
coor <- cbind(as.numeric(as.character(gr.coor$Long)), as.numeric(as.character(gr.coor$Lat)))

## Setting the coordinates system as Long/Lat
cord.dec = SpatialPoints(cbind(coor[,1], coor[,2]), proj4string=CRS("+proj=longlat +datum=WGS84 +no_defs +ellps=WGS84"))


## Most of this code came from http://envirem.github.io/ENVIREM_tutorial.html
## I don't to run Chelsa.Clim.download because I already did it. Below is the path 
## Where the raster are
Chelsa.Clim.download(parameter = "bio",
                     bio.var =  c(1:19), 
                     version.var = "1.2", 
                     clipping = FALSE, 
                     clip.extent = c(-81.5, -77.6, -7, 1.5), 
                     buffer = 0, 
                     convert.files.to.asc = FALSE, 
                     stacking.data = TRUE, 
                     combine.raw.zip = FALSE,
                     delete.raw.data = FALSE,
                     save.bib.file = TRUE)

## Setting the directory where the clipped raster was saved
wd <- ("C:\\Users\\Daniel\\Dropbox\\Thesis\\Molecular_Wrens\\Radseq\\IBE\\bio\\bio_V1.2\\clipped\\")

## Creating a list with the names of all raster files 
list.raster <- list.files(wd, full.names = TRUE)

## Reading and stacking the rasters
stack.ch <- stack(list.raster[1:19])

## Extracting the values for the sampling points I have
values.ch <- raster::extract(stack.ch, cord.dec)

## Naming the columns
colnames(values.ch) <- c("AMT","MDR","ISO","TS","MTWM","MTCM","TAR","MTWetQ","MTDQ","MTWarQ","MTCQ","AMP","PWetM","PDM","PS","PWetQ","PDQ","PWarQ","PCQ")

## Merging the coordinates, Chelsa values, population labels
coor.clim.raw.ch <- cbind.data.frame(coordinates(coor), values.ch)
colnames(coor.clim.raw.ch)[1:2] <- c("Long", "Lat")
coor.clim.raw.ch <- cbind(gr.coor, coor.clim.raw.ch)

View(coor.clim.raw.ch)
################################################################################

## Getting NDVI

install.packages("MODISTools")
library(MODISTools)

## View Variables we could use
View(mt_products())
View(mt_bands(product = "ECO4ESIPTJPL"))
View(mt_dates(product = "MOD13Q1", lat=coor[1,2], lon=coor[1,1]))


## Products
    # Bands

## MOD13Q1: MODIS/Aqua Vegetation Indices (NDVI/EVI) 16-Day L3 Global 250m SIN Grid
    # 250m_16_days_EVI
    # 250m_16_days_NDVI

## MOD15A2H: MODIS/Terra Leaf Area Index/FPAR (LAI/FPAR) 8-Day L4 Global 500 m SIN Grid
    # Lai_500m

## ECO4ESIPTJPL: ECOSTRESS Evaporative Stress Index PT-JPL (ESI) Daily L4 Global 70 m
    # ESIavg
    # PET

## Getting the coordinates data frame in the right format for the app
coor.mt <- gr.coor
colnames(coor.mt) <- c("site_name", "lat", "lon")

## Running MODISTools to get EVI
evi_raw <- mt_batch_subset(df=coor.mt, product="MOD13Q1",
                           band="250m_16_days_EVI",
                           internal=TRUE,
                           start="2018-01-01",
                           end="2018-12-19")

ndvi_raw <- mt_batch_subset(df=coor.mt, product="MOD13Q1",
                           band="250m_16_days_NDVI",
                           internal=TRUE,
                           start="2018-01-01",
                           end="2018-12-19")

lai_raw <- mt_batch_subset(df=coor.mt, product="MOD15A2H",
                           band="Lai_500m",
                           internal=TRUE,
                           start="2018-01-01",
                           end="2018-12-19")  

esi_raw <- mt_batch_subset(df=coor.mt, product="ECO4ESIPTJPL",
                           band="ESIavg",
                           internal=TRUE,
                           start="2018-01-01",
                           end="2018-12-19") 

pet_raw <- mt_batch_subset(df=coor.mt, product="ECO4ESIPTJPL",
                           band="PET",
                           internal=TRUE,
                           start="2018-01-01",
                           end="2018-12-19")                  

detach(package:plyr)# sometimes plyr package don't let summarise to work

## Getting a summary
library(plyr)

## Checking data
View(head(evi_raw))

## Getting the mean, sd and min of EVI
evi_sum <- evi_raw %>%
  dplyr::group_by(site) %>%
  dplyr::summarise(evi = mean(value, na.rm=TRUE),
            evi_sd = sd(value, na.rm=TRUE),
            evi_min = min(value, na.rm=TRUE))

## Getting the mean, sd and min of NDVI
ndvi_sum <- ndvi_raw %>%
  dplyr::group_by(site) %>%
  dplyr::summarise(ndvi = mean(value, na.rm=TRUE),
            ndvi_sd = sd(value, na.rm=TRUE),
            ndvi_min = min(value, na.rm=TRUE))

## Getting the mean, sd and min of LAI
lai_sum <- lai_raw %>%
  dplyr::group_by(site) %>%
  dplyr::summarise(lai = mean(value, na.rm=TRUE),
            lai_sd = sd(value, na.rm=TRUE),
            lai_min = min(value, na.rm=TRUE))

## Merging the data frames
veg_sum <- merge(evi_sum, ndvi_sum, by="site")
veg_sum <- merge(veg_sum, lai_sum, by="site")

## Check data
View(veg_sum)

##### Getting reduced columns
IV.ch <- coor.clim.raw.ch[,c(1,6,17,20)]

## Merging group name and climate
gr.iv <- merge(env[,c("Group", "Pop", "Lat", "Long", "Alt")], IV.ch, by="Group")
colnames(gr.iv)[1:2] <- c("Group", "Pop")

## Merging the climate and evi variables
gr.iv <- merge(gr.iv, veg_sum, by.x="Group", by.y="site", all.x=TRUE)

## Merging genetic spatial and climate
pop.order <- merge(gen.spatial, gr.iv, by=c("Group"))

## Ordering by Latitude
pop.order <- pop.order[order(-pop.order$AMP),]

## Sites order
site_order_clim <- unique(pop.order$Pop.y)

## Merging all data of aggression variables and climate
Exp.all.clim <- merge(Exp.gc, gr.iv, by.x="Group.x", by.y="Group")

## Deleting rows for Exp PB028. There was two Exp for this group
## I'm deleting the first one.
Exp.all.clim <- Exp.all.clim[!grepl("PB028", Exp.all.clim$Exp),]

dim(Exp.all.clim)

######################      MASTER DATAFRAME      ##############################            
## join Number of individuals in Exp and variables
colnames(Exp.all.clim)[c(1,5)] <- c("Group", "Treatment")

## Reading data for the description of experiments (metadata)
Meta.exp.raw <- read.csv("Exp.csv", sep=",", header=TRUE, as.is=T)

## Adding the meta info to the data
Exp.all.clim <- merge(Exp.all.clim, Meta.exp.raw, by="Group")

dim(Exp.all.clim)

#################################################################################

colnames(Exp.all.clim)

## Making GC a dummy variable
Exp.all.clim$GC_d <- ifelse(Exp.all.clim$GC == "CZ", 1, 
ifelse(Exp.all.clim$GC == "CFP_N", 2, 3))

## Making Treatment a dummy variable
Exp.all.clim$Treatment_d <- ifelse(Exp.all.clim$Treatment == "BBWR", 1, 0)

## Inv has NA in it, changing to one, we assume there was at least one individual responding.
## These was speially in BBWR where I found single individuals
Exp.all.clim$Inv[is.na(Exp.all.clim$Inv)] <- 1

## Scaling the variables
Exp.all.clim$Dist_sc <- scale(Exp.all.clim$Dist, center = TRUE)
Exp.all.clim$Timing_sec_sc <- scale(Exp.all.clim$Timing_sec)
Exp.all.clim$TFAP_sc <- scale(Exp.all.clim$TFAP)
Exp.all.clim$AMT_sc <- scale(Exp.all.clim$AMT)
Exp.all.clim$AMP_sc <- scale(Exp.all.clim$AMP)
Exp.all.clim$PS_sc <- scale(Exp.all.clim$PS)
Exp.all.clim$Lat_sc <- scale(Exp.all.clim$Lat)
Exp.all.clim$Long_sc <- scale(Exp.all.clim$Long)
Exp.all.clim$evi_sd_sc <- scale(Exp.all.clim$evi_sd)
Exp.all.clim$evi_sc <- scale(Exp.all.clim$evi)
Exp.all.clim$evi_min_sc <- scale(Exp.all.clim$evi_min)
Exp.all.clim$ndvi_sc <- scale(Exp.all.clim$ndvi)
Exp.all.clim$ndvi_sd_sc <- scale(Exp.all.clim$ndvi_sd)
Exp.all.clim$ndvi_min_sc <- scale(Exp.all.clim$ndvi_min)
Exp.all.clim$lai_sc <- scale(Exp.all.clim$lai)
Exp.all.clim$lai_sd_sc <- scale(Exp.all.clim$lai_sd)
Exp.all.clim$lai_min_sc <- scale(Exp.all.clim$lai_min)
Exp.all.clim$Inv_sc <- as.vector(scale(Exp.all.clim$Inv))


## Make variables greater than zero to adjust to dexp
Exp.all.clim$TFAP_pos <- Exp.all.clim$TFAP_sc + abs(min(Exp.all.clim$TFAP_sc, na.rm=TRUE)) + 1
Exp.all.clim$Dist_pos <- Exp.all.clim$Dist_sc + abs(min(Exp.all.clim$Dist_sc, na.rm=TRUE)) + 1
Exp.all.clim$Latency_pos <- Exp.all.clim$Timing_sec_sc + abs(min(Exp.all.clim$Timing_sec_sc, na.rm=TRUE)) + 1

# replace NA with zeros in the data
Exp.all.clim$Latency_pos[is.na(Exp.all.clim$Latency_pos)] <- 0.1

dim(Exp.all.clim)
colnames(Exp.all.clim)
View(Exp.all.clim)

#################################################################################
## Adding plant diversity data

## Path to the raster files
path.plRich <- "C:/Users/Daniel/Dropbox/Thesis/Aggressive Behavior/R/3506_70_Dataset/"

library(raster)

## Read the raster w3_tile_joint_sr1000.tif at path.plRich
r <- raster(paste0(path.plRich, "w3_tile_joint_sr1000.tif"))

## Extract values of r using cord.dec
values.r <- raster::extract(r, cord.dec)

## Adding group name to the raster values
values.r <- cbind(gr.coor, values.r)

View(values.r)

## Merging group name and climate
Exp.all.clim <- merge(Exp.all.clim, values.r, by="Group")

colnames(Exp.all.clim)

## scale plant richness
Exp.all.clim$Rich_sc <- as.vector(scale(Exp.all.clim$values.r))

#################################################################################

## Get loading of PCA for primary productivity

colnames(Exp.all.clim)
prod.var <- c("evi_sc", "evi_sd_sc", "evi_min_sc",
"ndvi_sc", "ndvi_sd_sc", "ndvi_min_sc",
"lai_sc", "lai_sd_sc", "lai_min_sc", "Rich_sc")


######################      PCA VEG      ###########################################

## Getting the PCA veg1
pca.veg <- prcomp(Exp.all.clim[,prod.var], scale=TRUE)
summary(pca.veg)

plot(pca.veg)

## Make a staylish Plot of the loadings for publication 
## (https://www.r-graph-gallery.com/82-r-plot-pca-variance-explained/)
library(ggplot2)
library(ggpubr)

## Get the data
data.var <- as.data.frame(pca.veg$rotation)

## Add a column with the variable names
data.var$var <- rownames(data.var)

## Get the percentage of variance explained by each variable
data.var$variance <- pca.veg$sdev^2/sum(pca.veg$sdev^2)*100

## Get the position of the text
data.var$hjust <- ifelse(data.var$PC1 > 0, 0, 1)
data.var$vjust <- ifelse(data.var$PC2 > 0, 1, 0)
data.var$hjust[data.var$var == "evi"] <- 1
data.var$hjust[data.var$var == "evi_sd"] <- 1
data.var$hjust[data.var$var == "evi_min"] <- 1
data.var$hjust[data.var$var == "ndvi_sc"] <- 1
data.var$hjust[data.var$var == "ndvi_sd_sc"] <- 1
data.var$hjust[data.var$var == "ndvi_min_sc"] <- 1
data.var$hjust[data.var$var == "lai_sc"] <- 1
data.var$hjust[data.var$var == "lai_sd_sc"] <- 1
data.var$hjust[data.var$var == "lai_min_sc"] <- 1
data.var$hjust[data.var$var == "Rich_sc"] <- 1

## Make the plot
pprod.pca <- ggplot(data.var, aes(x=PC1, y=PC2)) +
  geom_hline(yintercept=0, linetype="dashed") +
  geom_vline(xintercept=0, linetype="dashed") +
  geom_point(aes(size=variance), color="blue", alpha=0.6) +
  geom_text(aes(label=var, hjust=hjust, vjust=vjust), 
  position = position_dodge(width=0.2), size=6) +
  scale_size_continuous(range = c(2, 10)) +
  labs(x="PC1 (44.5%)", y="PC2 (22.5%)") +
  theme(legend.position="none") +
  theme(text = element_text(size=20))

  ## Gitter the the position of labels to avoid overlap with points
    pprod.pca + geom_text(aes(label=var, hjust=hjust, vjust=vjust),
    position = position_jitter(width=0.2, height=0.2), size=7)

## Getting the first pc1
Exp.all.clim$pca.veg1 <- pca.veg$x[,1]

## Getting the second pc2
Exp.all.clim$pca.veg2 <- pca.veg$x[,2]

## PCA with climate variables
pca.clim.var <- c("AMT", "AMP", "PS")


######################      PCA CLIM      ###########################################

## Getting the PCA
pca.clim <- prcomp(Exp.all.clim[,pca.clim.var], scale=TRUE)
summary(pca.clim)

## getting the first pc1
Exp.all.clim$pca.clim1 <- pca.clim$x[,1]

## Getting the second pc2
Exp.all.clim$pca.clim2 <- pca.clim$x[,2]

## Make a staylish Plot of the pca with pca.clim of the loadings for publication 
## (https://www.r-graph-gallery.com/82-r-plot-pca-variance-explained/)
library(ggplot2)
library(ggpubr)

## Get the data
data.var1 <- as.data.frame(pca.clim$rotation)

## Add a column with the variable names
data.var1$var <- rownames(data.var1)

## Get the percentage of variance explained by each variable
data.var1$variance <- pca.clim$sdev^2/sum(pca.clim$sdev^2)*100

## Get the position of the text
data.var1$hjust <- ifelse(data.var1$PC1 > 0, 0, 1)
data.var1$vjust <- ifelse(data.var1$PC2 > 0, 1, 0)
data.var1$hjust[data.var1$var == "AMT"] <- 1
data.var1$hjust[data.var1$var == "AMP"] <- 1
data.var1$hjust[data.var1$var == "PS"] <- 1

## Make the plot
pclim.pca <- ggplot(data.var1, aes(x=PC1, y=PC2)) +
  geom_hline(yintercept=0, linetype="dashed") +
  geom_vline(xintercept=0, linetype="dashed") +
  geom_point(aes(size=variance), color="blue", alpha=0.6) +
  geom_text(aes(label=var, hjust=hjust, vjust=vjust), 
  position = position_dodge(width=0.2), size=6) +
  scale_size_continuous(range = c(2, 10)) +
  labs(x="PC1 (44.5%)", y="PC2 (22.5%)") +
  theme(legend.position="none") +
  theme(text = element_text(size=20))

  ## Gitter the the position of labels to avoid overlap with points
    pclim.pca + geom_text(aes(label=var, hjust=hjust, vjust=vjust),
    position = position_jitter(width=0.2, height=0.2), size=7)

#################################################################################








##  Remove Observation.y from Exp.all.clim
Exp.all.clim <- Exp.all.clim[,c(1:33, 35:ncol(Exp.all.clim))]

## Getting the variables for the GDM
Exp.mv.clim <- Exp.all.clim %>%
  dplyr::group_by(Group) %>%
  dplyr::summarise(MinDist1=min(Dist, na.rm=TRUE),
            Latency1=mean(Timing_sec, na.rm=TRUE),
            TFAP1=sum(TFAP, na.rm=TRUE),
            AMT1=mean(AMT, na.rm=TRUE),
            AMP1=mean(AMP, na.rm=TRUE),
            PS1=mean(PS, na.rm=TRUE),
            Lat1=mean(Lat, na.rm=TRUE),
            Long1=mean(Long, na.rm=TRUE),
            evi1=mean(evi, na.rm=TRUE),
            evi_min1=min(evi_min, na.rm=TRUE),
            ndvi1=mean(ndvi, na.rm=TRUE),
            ndvi_min1=min(ndvi_min, na.rm=TRUE),
            lai1=mean(lai, na.rm=TRUE),
            lai_min1=min(lai_min, na.rm=TRUE),
            Inv1=mean(Inv, na.rm=TRUE),
            Rich1=mean(values.r, na.rm=TRUE),
            pca.veg11=mean(pca.veg1, na.rm=TRUE),
            pca.veg12=mean(pca.veg2, na.rm=TRUE),
            pca.clim11=mean(pca.clim1, na.rm=TRUE),
            pca.clim12=mean(pca.clim2, na.rm=TRUE))

## Remove the ones from colnames in  EXp.mv.clim
colnames(Exp.mv.clim)[c(2:21)] <- c("MinDist", 
"Latency", 
"TFAP", 
"AMT", 
"AMP", 
"PS", 
"y", 
"x", 
"evi", 
"evi_min", 
"ndvi", 
"ndvi_min", 
"lai", 
"lai_min", 
"Inv", 
"Rich", 
"pca.veg1", 
"pca.veg2", 
"pca.clim1", 
"pca.clim2")

## Order Exp.mv.clim by GRoup
Exp.mv.clim <- Exp.mv.clim[order(Exp.mv.clim$Group),]

## Get the variable with pca
Exp.gdm.pred <- as.data.frame(Exp.mv.clim[,c("Group", "x", "y", "pca.veg1", "pca.veg2", "pca.clim1", "pca.clim2")])
dim(Exp.gdm.pred)
head(Exp.gdm.pred)

## Get the variable without pca
Exp.gdm.pred2 <- as.data.frame(Exp.mv.clim[,c("Group", "x", "y", "AMT", "AMP", "PS", "pca.veg1", "pca.veg2")])
dim(Exp.gdm.pred2)
head(Exp.gdm.pred2)

## get the variables with sc in Exp.all.clim
Exp.pred.sc <- Exp.all.clim[,c("Group", "Lat.y", "Long.y", "Dist", "Dist_sc",
"Timing_sec", "Timing_sec_sc", "TFAP", "TFAP_sc", "AMT_sc", "AMP_sc", "PS_sc",
"evi", "evi_sd", "evi_min", "ndvi", "ndvi_sd", "ndvi_min", "lai", "lai_sd", "lai_min", "values.r",
"evi_sc", "evi_sd_sc", "evi_min_sc", "ndvi_sc", "ndvi_sd_sc", "ndvi_min_sc", "lai_sc", "lai_sd_sc", "lai_min_sc", "Rich_sc",
"Inv_sc", "pca.veg1", "pca.veg2", "pca.clim1", "pca.clim2")]

## Make variables greater than zero to adjust to dexp
Exp.pred.sc$TFAP_pos <- Exp.pred.sc$TFAP_sc + abs(min(Exp.pred.sc$TFAP_sc, na.rm=TRUE)) + 1
Exp.pred.sc$Dist_pos <- Exp.pred.sc$Dist_sc + abs(min(Exp.pred.sc$Dist_sc, na.rm=TRUE)) + 1



```

## DEFINITIONS OF PRIMARY PRODUCTIVITY VARIABLES

Landsat Enhanced Vegetation Index (EVI) is similar to Normalized Difference Vegetation Index (NDVI) 
and can be used to quantify vegetation greenness. However, EVI corrects for some atmospheric conditions
 and canopy background noise and is more sensitive in areas with dense vegetation.

The NDVI index detects and quantifies the presence of live green vegetation using this reflected light 
in the visible and near-infrared bands. Put simply, NDVI is an indicator of the vegetation 
greenness —the density and health—of each pixel in a satellite image.

LAI is defined as the one-sided green leaf area per unit ground area in broadleaf canopies and as 
one-half the total needle surface area per unit ground area in coniferous canopies.

The ESI is an indicator of potential drought and plant water stress emphasizing areas of sub-optimal plant productivity.
The ESI product is derived from the ratio of the Level 3 actual evapotranspiration (ET) to potential ET (PET) 
calculated as part of the algorithm. The ESI is an indicator of potential drought and plant water stress. 
emphasizing areas of sub-optimal plant productivity.


#### Testing Normality for response variables

```{r Testing Normality}

## Exploring Normality ####

## Intalling ggpbur for nice plots
install.packages("ggpubr")
library(ggpubr)

## With Minimum Distance
ggdensity(Exp.all.clim$Dist)
ggdensity(scale(Exp.all.clim$Dist))

ggqqplot(Exp.all.clim$Dist)
shapiro.test(Exp.all.clim$Dist)

ggqqplot(log(Exp.all.clim$Dist+1))
ggdensity(log(Exp.all.clim$Dist+1))
shapiro.test(log(Exp.all.clim$Dist+1))

ggqqplot(sqrt(Exp.all.clim$Dist_sc+1))
shapiro.test(sqrt(Exp.all.clim$Dist+1))

ggqqplot(sqrt((max(Exp.all.clim$Dist+1)+1)-(Exp.all.clim$Dist+1)))
shapiro.test(sqrt((max(Exp.all.clim$Dist+1)+1)-(Exp.all.clim$Dist+1)))

ggqqplot(exp(Exp.all.clim$Dist_sc+1))
shapiro.test(exp(Exp.all.clim$Dist+1))

ggqqplot(1/max(Exp.all.clim$Dist_sc+1)^2+1)
shapiro.test(exp(Exp.all.clim$Dist+1))

## With Latency
ggdensity(Exp.all.clim$Timing_sec)
ggdensity(scale(Exp.all.clim$Dist))

ggqqplot(Exp.all.clim$Dist)
shapiro.test(Exp.all.clim$Dist)

ggqqplot(log(Exp.all.clim$Dist+1))
shapiro.test(log(Exp.all.clim$Dist+1))

ggqqplot(sqrt(Exp.all.clim$Dist))
shapiro.test(sqrt(Exp.all.clim$Dist))

## With TFAP
ggdensity(Exp.gc$TFAP)
ggdensity(scale(Exp.gc$TFAP))

ggqqplot(Exp.gc$TFAP)
shapiro.test(Exp.gc$TFAP)

ggqqplot(Exp.mv.clim$MinDist_sc)
ggqqplot(Exp.mv.clim$Latency_sc)
ggqqplot(Exp.mv.clim$TFAP_sc)
shapiro.test(Exp.mv.clim$TFAP_sc)

plot(density(Exp.mv.clim$MinDist_sc))
plot(density(Exp.mv.clim$Latency_sc))
plot(density(Exp.mv.clim$TFAP_sc))
plot(density(Exp.mv.clim$pca1))
plot(density(Exp.mv.clim$pca2))

hist(Exp.mv.clim$MinDist_sc, breaks=10)
hist(Exp.mv.clim$Latency_sc, breaks=10)
hist(Exp.mv.clim$TFAP_sc, breaks=10)

ggdensity(dexp(Exp.all.clim$Dist_sc, 1))
ggdensity(Exp.all.clim$Dist_sc)


mean(abs(Exp.all.clim$Dist_sc))
dexp(Exp.all.clim$Dist_sc,1)
dexp(-0.5,1)

```
None of the variables follow a normal distribution

```{r PCA correlations}

## PCA correlations ####

## climate productivity variables
cor(Exp.all.clim[,c(56:64,93:98,105:108)], use="complete.obs", method="pearson")

## Correlations among primary productivity variables
cor.pprod <- rcorr(as.matrix(Exp.all.clim[,c(56:64,93:98,105:108)]), type = c("pearson"))

## See what variables are correlated significantly
View(as.matrix(cor.pprod$P))

## See pvalues for the pca.veg1 and pca.veg2
View(t(cor.pprod$P[18:19,]))

library(PerformanceAnalytics)

chart.Correlation(Exp.all.clim[,c(56:64,93:98,105:108)], histogram=TRUE, pch=22)

colnames(Exp.all.clim)


```

pca.veg1 correlated significantly with lai and richness variables

```{r SEM: pca.veg1}

## Required libraries
library(blavaan)
library(semPlot)

m.tfap.pcaveg1 <- '
## Measurement model
Aggr =~ TFAP + Dist_sc

# Regression-Structural model
Aggr ~ pca.veg1 + PS_sc + AMP_sc + Inv_sc

# Mediator
pca.veg1 ~ PS_sc + AMP_sc

# Covariances
PS_sc ~~ AMP_sc
'

# Fitting hte model
out.tfap.full <- bsem(m.tfap.pcaveg1, data=Exp.pred.sc, fixed.x = FALSE)

## Summary Results
summary(out.tfap.full, fit.measures=TRUE)

## With semPlot
semPaths(out.tfap.full, what= "stand", style="lisrel", layout="tree2", rotation=1, reorder = TRUE)
dev.off()

## With tidySEM
install.packages("tidySEM")
library(tidySEM)

lay <- get_layout("PS_sc","","Inv_sc","TFAP",
                  "","pca.veg1","Aggr","",
                  "AMP_sc","","","Dist_sc", rows = 3)

## Default S3 method:
graph_sem(out.tfap.full, layout=lay
                , spacing_y=1
                , variance_diameter=0.3
                , angle=45
                , ellipses_width = 0.6
                , ellipses_height = 0.6
                , rect_width = 0.8
                , rect_height = 0.4
                , text_size = 5)


```


```{r SEM: pca.veg2}


m.tfap.pcaveg2 <- '
## Measurement model
Aggr =~ TFAP + Dist_sc

# Regression-Structural model
Aggr ~ pca.veg2 + PS_sc + AMP_sc + Inv_sc

# Mediator
pca.veg2 ~ PS_sc + AMP_sc

# Covariances
PS_sc ~~ AMP_sc
'

# Fitting hte model
out.tfap.full2 <- bsem(m.tfap.pcaveg2, data=Exp.pred.sc, fixed.x = FALSE)

## Summary Results
summary(out.tfap.full2, fit.measures=TRUE)

## With semPlot
semPaths(out.tfap.full2, what= "stand", style="lisrel", layout="tree2", rotation=1, reorder = TRUE)
dev.off()

## With tidySEM
install.packages("tidySEM")
library(tidySEM)

lay2 <- get_layout("PS_sc","","Inv_sc","TFAP",
                  "","pca.veg2","Aggr","",
                  "AMP_sc","","","Dist_sc", rows = 3)

## Default S3 method:
graph_sem(out.tfap.full2, layout=lay2
                , spacing_y=1
                , variance_diameter=0.3
                , angle=45
                , ellipses_width = 0.6
                , ellipses_height = 0.4
                , rect_width = 0.8
                , rect_height = 0.4
                , text_size = 5)


```


```{r SEM: pca.clim1}


m.veg1.clim1 <- '
## Measurement model
Aggr =~ TFAP + Dist_sc

# Regression-Structural model
Aggr ~ pca.veg1 + pca.clim1 + Inv_sc

# Mediator
pca.veg1 ~ pca.clim1

# Covariances
PS_sc ~~ AMP_sc
'

m.veg2.clim1 <- '
## Measurement model
Aggr =~ TFAP + Dist_sc

# Regression-Structural model
Aggr ~ pca.veg2 + pca.clim1 + Inv_sc

# Mediator
pca.veg2 ~ pca.clim1

# Covariances
PS_sc ~~ AMP_sc
'

# Fitting hte model
out.veg1.clim1 <- bsem(m.veg1.clim1, data=Exp.pred.sc, fixed.x = FALSE)

# Fitting the model
out.veg2.clim1 <- bsem(m.veg2.clim1, data=Exp.pred.sc, fixed.x = FALSE)

## Summary Results
summary(out.veg1.clim1, fit.measures=TRUE)

## Summary Results
summary(out.veg2.clim1, fit.measures=TRUE)

## With semPlot
library(semPlot)
semPaths(out.clim1, what= "stand", style="lisrel", layout="tree2", rotation=1, reorder = TRUE)
dev.off()

## With tidySEM
install.packages("tidySEM")
library(tidySEM)

lay3 <- get_layout("","","Inv_sc","TFAP",
                  "pca.clim1","pca.veg2","Aggr","",
                  "","","","Dist_sc", rows = 3)

## Default S3 method:
graph_sem(out.veg2.clim1, layout=lay3
                , spacing_y=1
                , variance_diameter=0.3
                , angle=45
                , ellipses_width = 0.6
                , ellipses_height = 0.4
                , rect_width = 0.8
                , rect_height = 0.4
                , text_size = 5)



```


```{r SEM: pca.clim2}

m.veg1.clim2 <- '
## Measurement model
Aggr =~ TFAP + Dist_sc

# Regression-Structural model
Aggr ~ pca.veg1 + pca.clim2 + Inv_sc

# Mediator
pca.veg1 ~ pca.clim2

# Covariances
'

m.veg2.clim2 <- '
## Measurement model
Aggr =~ TFAP + Dist_sc

# Regression-Structural model
Aggr ~ pca.veg2 + pca.clim2 + Inv_sc

# Mediator
pca.veg2 ~ pca.clim2

# Covariances
'

# Fitting hte model
out.veg1.clim2 <- bsem(m.veg1.clim2, data=Exp.pred.sc, fixed.x = FALSE)

# Fitting hte model
out.veg2.clim2 <- bsem(m.veg2.clim2, data=Exp.pred.sc, fixed.x = FALSE)

## Summary Results
summary(out.veg1.clim2, fit.measures=TRUE)

## Summary Results
summary(out.veg2.clim2, fit.measures=TRUE)


## With semPlot
library(semPlot)
semPaths(out.clim2, what= "stand", style="lisrel", layout="tree2", rotation=1, reorder = TRUE)
dev.off()

## With tidySEM
install.packages("tidySEM")
library(tidySEM)

lay4 <- get_layout("","","Inv_sc","TFAP",
                  "pca.clim2","pca.veg2","Aggr","",
                  "","","","Dist_sc", rows = 3)

## Default S3 method:
graph_sem(out.veg2.clim2, layout=lay4
                , spacing_y=1
                , variance_diameter=0.3
                , angle=45
                , ellipses_width = 0.6
                , ellipses_height = 0.4
                , rect_width = 0.8
                , rect_height = 0.4
                , text_size = 5)

```


```{r Outcomes and Plotting}

# Make a plot for publication for Exp.pred.sc$evi, Exp.pred.sc$TFAP
ggplot(Exp.pred.sc, aes(x=evi, y=TFAP)) +
  geom_point(aes(size=Dist), color="blue", alpha=0.6)+
  scale_size_continuous(range = c(2, 10)) +
  labs(x="EVI", y="TFAP") +
  theme(text = element_text(size=24))

ggplot(Exp.pred.sc, aes(x=evi, y=Dist)) +
  geom_point(aes(size=Dist), color="blue", alpha=0.6)+
  scale_size_continuous(range = c(2, 10)) +
  labs(x="EVI", y="Minimum Distance") +
  theme(text = element_text(size=24))


## export as jpg previous plot
ggsave("C:/Users/Daniel/Dropbox/Thesis/Aggressive Behavior/lat_evi.jpg", width = 15, height = 10, units = "in")

## Plot evi and lat with publication quality
ggplot(Exp.all.clim, aes(x=Lat.y, y=evi)) +
  geom_point(aes(size=AMP), color="blue", alpha=0.6)+
  scale_size_continuous(range = c(2, 10)) +
  labs(x="Latitude", y="Evi") +
  theme(text = element_text(size=40))


## export as jpg previous plot
ggsave("C:/Users/Daniel/Dropbox/Thesis/Aggressive Behavior/evi_inv.jpg", width = 15, height = 10, units = "in")

## Plot evi and lat with publication quality
ggplot(Exp.all.clim, aes(x=evi, y=Inv)) +
  geom_point(aes(size=TFAP), color="blue", alpha=0.6)+
  scale_size_continuous(range = c(2, 10)) +
  labs(x="EVI", y="Group Size") +
  theme(text = element_text(size=24))



######################      MAPPING      ###########################################


## Make a plot of the raster with evi values across western Ecuador
library(raster)
library(ggplot2)
library(ggpubr)

## CLIMATE

## Setting the directory where the clipped raster was saved
wd <- ("C:\\Users\\Daniel\\Dropbox\\Thesis\\Molecular_Wrens\\Radseq\\IBE\\bio\\bio_V1.2\\clipped\\")

## Creating a list with the names of all raster files 
list.clim <- list.files(wd, full.names = TRUE)

## BIO1: Annual Mean Temperature
## BIO12: Annual Precipitation
## BIO15: Precipitation Seasonality (Coefficient of Variation)

## Make a extent object for the region of interest
reg <- as(extent(-81, -79.5, -4.5, 0.6), 'SpatialPolygons')

## Read shapefile for west region
west <- readOGR("C:/Users/Daniel/Dropbox/Thesis/Aggressive Behavior/R/SHP/West1.shp")

# Cutting the mosaic manually giving coordinates to the extent
r1 <- raster(list.clim[1])
crs(reg) <- crs(r1)
reg.amt <- crop(r1, reg)
plot(reg.amt)

# Cutting the mosaic manually giving coordinates to the extent
r12 <- raster(list.clim[12])
crs(reg) <- crs(r12)
reg.amp <- crop(r12, reg)
plot(reg.amp)

# Cutting the mosaic manually giving coordinates to the extent
r15 <- raster(list.clim[15])
crs(reg) <- crs(r15)
reg.ps <- crop(r15, reg)
plot(reg.ps)

## Make a poligon grid of 100 km x 100 km for the region of interest reg
reg.grid <- rasterToPolygons(reg, n=100, dissolve=TRUE)
plot(reg.grid)
str(reg.grid)



install.packages("geosphere")
library(geosphere)

## estimate distancce in kilometer from -4.5 to 0.6 degrees
dist.left_right <- round(distHaversine(c(-81, 0.6), c(-79.5, 0.6), r=6378137)/1000)

## estimate distancce in kilometer from -81 to -79.5 degrees
dist.up_down <- round(distHaversine(c(-81, 0.6), c(-81, -4.5), r=6378137)/1000)


?coordinates

library(MODISTools)

## Running MODISTools to get EVI
evi_reg <- mt_subset(product="MOD13Q1",
                           lat = 0.6,
                           lon = -81,
                           band="250m_16_days_EVI",
                           km_lr = 10,
                           km_ab = 10,
                           internal=TRUE,
                           start="2018-01-01",
                           end="2018-12-19")

str(evi_reg)


## convert dataframe to raster
evi_reg.r <- rasterFromXYZ(evi_reg, crs="+proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0")




ndvi_reg <- mt_batch_subset(df=coor.mt, product="MOD13Q1",
                           band="250m_16_days_NDVI",
                           internal=TRUE,
                           start="2018-01-01",
                           end="2018-12-19")

lai_reg <- mt_batch_subset(df=coor.mt, product="MOD15A2H",
                           band="Lai_500m",
                           internal=TRUE,
                           start="2018-01-01",
                           end="2018-12-19")  


View(coor.mt)
str(coor.mt)
class(coor.mt)

str(reg.coor)


## map the following equation Aggr = alpha + beta*pca.veg1 + beta*PS_sc + beta*AMP_sc + beta*Inv_sc + epsilon
## where alpha is the intercept, beta is the slope, and epsilon is the error term








## Path to the raster files
path.evi <- "C:/Users/Daniel/Dropbox/Thesis/Aggressive Behavior/R/3506_70_Dataset/"


















```


```{r SEM: evi_sc}

m.tfap.evi <- '
## Measurement model
Aggr =~ TFAP + Dist_sc

# Regression-Structural model
Aggr ~ evi_sc + PS_sc + AMP_sc + Inv_sc

# Mediator
evi_sc ~ PS_sc + AMP_sc

# Covariances
PS_sc ~~ AMP_sc
'

# Fitting hte model
out.tfap.full3 <- bsem(m.tfap.evi, data=Exp.pred.sc, fixed.x = FALSE)

## Summary Results
summary(out.tfap.full3, fit.measures=TRUE)

## With semPlot
semPaths(out.tfap.full3, what= "stand", style="lisrel", layout="tree2", rotation=1, reorder = TRUE)
dev.off()

## With tidySEM
install.packages("tidySEM")
library(tidySEM)

lay3 <- get_layout("TFAP","","Dist_sc",
                "Inv_sc","Aggr","",
                "","evi_sc","",
                "PS_sc","", "AMP_sc", rows = 4)

## Default S3 method:
graph_sem(out.tfap.full3, layout=lay3
                , spacing_y=1
                , variance_diameter=0.3
                , angle=45,
                , ellipses_width = 0.6
                , ellipses_height = 0.6,
                , rect_width = 0.8
                , rect_height = 0.4
                , text_size = 7)




```


#### Saving

```{r Saving}

save.image('GDM_data.RData')
save.image('GDM_out.RData')

```

#### 
 

  



